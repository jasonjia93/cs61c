ec2 Experience

1. How long did each of the six runs take? How many mappers and how many reducers did you use?

	Run 1
		Job 1
			Run Time: 12 mins, 49 secs
			Mappers: 80
			Reducers: 32
		Job2
			Run Time: 27 secs
			Mappers: 32
			Reducers: 1
		Total:
			Run Time: 13 mins, 16 secs
			Mappers: 112
			Reducers: 33

	Run 2
		Job 1
			Run Time: 5 mins, 49 secs
			Mappers: 80
			Reducers: 32
		Job2
			Run Time: 31 secs
			Mappers: 32
			Reducers: 1
		Total:
			Run Time: 6 mins, 20 secs
			Mappers: 112
			Reducers: 33

	Run 3
		Job 1
			Run Time: 18 mins, 3 secs
			Mappers: 316
			Reducers: 32
		Job2
			Run Time: 30 secs
			Mappers: 32
			Reducers: 1
		Total:
			Run Time: 18 mins, 33 secs
			Mappers: 348
			Reducers: 33

	Run 4
		Job 1
			Run Time: 10 mins, 49 secs
			Mappers: 316
			Reducers: 32
		Job2
			Run Time: 29 secs
			Mappers: 32
			Reducers: 1
		Total:
			Run Time: 11 mins, 18 secs
			Mappers: 348
			Reducers: 33

	Run 5
		Job 1
			Run Time: 11 mins, 4 secs
			Mappers: 316
			Reducers: 32
		Job2
			Run Time: 27 secs
			Mappers: 32
			Reducers: 1
		Total:
			Run Time: 11 mins, 31 secs
			Mappers: 348
			Reducers: 33

	Run 6
		Job 1
			Run Time: 10 mins, 54 secs
			Mappers: 316
			Reducers: 32
		Job2
			Run Time: 27 secs
			Mappers: 32
			Reducers: 1
		Total:
			Run Time: 11 mins, 21 secs
			Mappers: 348
			Reducers: 33


2. For the two runs with (freedom, 0), how much faster did your code run on the 5 workers with the combiner turned on than with the combiner turned off? Express your answer as a percentage.

	209.47%


3. For the runs on the 2006 dataset, what was the median processing rate per GB (= 2^30 bytes) of input for the tests using 5 workers? Using 9 workers?

	5 Workers: 62.44 seconds per GB
		0.016 GB/sec
	9 Workers: 38.20 seconds per GB
		0.0262 GB/sec


4. What was the percent speedup of running (capital, 0) with 9 workers over 5 workers? What is the maximum possible speedup, assuming your code is fully parallelizable? How well, in your opinion, does Hadoop parallelize your code? Justify your answer in 1-2 sentences.

	164.16%

	Assuming my code is fully parallelizable, the maxinum possible speedup would be essentially limitless. I could keep on adding workers, with each worker allowing my code to run faster until my code runs instantaneously.

	Hadoop parallelizes my code well but not perfectly. I added 180% (5 workers to 9 workers) more workers, but my code only sped up by 164%, meaning I could never make my code run instantaneously by adding more and more workers.


5. For a single run on the 2006 dataset, what was the price per GB processed on with 5 workers? With 9 workers? (Recall that an extra-large instance costs $0.58 per hour, rounded up to the nearest hour.)

	5 workers: $0.05/GB
		62.44/3600 * 5*(0.58)

	9 workers: $0.055/GB
		38.20/3600 * 9*(0.58)


6. How much total money did you use to complete this project?

	1 hour with 5 large clusters: 1 * 5(0.58) = $2.90
	1 hour with 9 large clusters: 1 * 9(0.58) = $5.22

	Total: $8.12
